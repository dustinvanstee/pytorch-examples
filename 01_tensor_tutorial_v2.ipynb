{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "#The line above is necesary to show Matplotlib's plots inside a Jupyter Notebook\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "What is PyTorch?\n",
    "================\n",
    "\n",
    "It’s a Python-based scientific computing package targeted at two sets of\n",
    "audiences:\n",
    "\n",
    "-  A replacement for NumPy to use the power of GPUs\n",
    "-  a deep learning research platform that provides maximum flexibility\n",
    "   and speed\n",
    "\n",
    "Getting Started\n",
    "---------------\n",
    "\n",
    "Tensors\n",
    "^^^^^^^\n",
    "\n",
    "Tensors are similar to NumPy’s ndarrays, with the addition being that\n",
    "Tensors can also be used on a GPU to accelerate computing.\n",
    "\n",
    "** Here are some high frequency operations you should get used to **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct a 5x3 matrix, uninitialized using [torch.empty]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.empty(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct a randomly initialized matrix using [torch.rand](https://pytorch.org/docs/stable/torch.html#torch.rand)\n",
    "\n",
    "Look at the documentation and see if you can make a 10,100 array or random numbers\n",
    "<details>\n",
    "<summary>Answer</summary>\n",
    "<p> torch.rand(10,100)</p></details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Fill me in\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print out the size of a tensor.  \n",
    "you will be doing this frequently if developing/debuggin a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct a matrix filled zeros and of dtype floating point 16.  Here is a link to available [types](https://pytorch.org/docs/stable/tensor_attributes.html#torch.torch.dtype)\n",
    "\n",
    "Can you change long to floating point16 below\n",
    "<details>\n",
    "<summary>Hint</summary>\n",
    "<p> torch.zeros(5, 3, dtype=torch.float16) </p></details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Element operations\n",
    "\n",
    "do an element wise add of A and B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.rand(5, 3)\n",
    "B = torch.rand(5, 3)\n",
    "\n",
    "print(A)\n",
    "print(B)\n",
    "print(A + B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternate method using torch.add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.add(A, B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addition: providing an output tensor as argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = torch.empty(5, 3)\n",
    "torch.add(A, B, out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addition: in-place\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### adds x to y\n",
    "B.add_(A)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>Any operation that mutates a tensor in-place is post-fixed with an ``_``.\n",
    "    For example: ``x.copy_(y)``, ``x.t_()``, will change ``x``.</p></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Multiply\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 1],\n",
      "        [0, 2, 1]])\n",
      "tensor([[1, 1],\n",
      "        [3, 3],\n",
      "        [0, 1]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randint(4,(2,3))\n",
    "b = torch.randint(4,(3,2))\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [6, 7]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2x3 @ 3x2 ~ 2x2\n",
    "a.matmul(b)\n",
    "torch.matmul(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a onehot vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8],\n",
      "        [ 1],\n",
      "        [ 4],\n",
      "        [ 5],\n",
      "        [ 7]])\n",
      "tensor([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 5\n",
    "nb_digits = 10\n",
    "# Dummy input that HAS to be 2D for the scatter (you can use view(-1,1) if needed)\n",
    "y = torch.LongTensor(batch_size,1).random_() % nb_digits\n",
    "# One hot encoding buffer that you create out of the loop and just keep reusing\n",
    "y_onehot = torch.FloatTensor(batch_size, nb_digits)\n",
    "\n",
    "# In your for loop\n",
    "y_onehot.zero_()\n",
    "y_onehot.scatter_(1, y, 1)\n",
    "\n",
    "print(y)\n",
    "print(y_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use argmax to grab the index of the highest value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.4791, 0.6427, 0.4850, 0.8918, 0.5046],\n",
      "         [0.3802, 0.1974, 0.8807, 0.3322, 0.3854],\n",
      "         [0.1450, 0.6710, 0.1567, 0.8760, 0.7838],\n",
      "         [0.9900, 0.4326, 0.6907, 0.3431, 0.7704]],\n",
      "\n",
      "        [[0.6741, 0.7869, 0.0707, 0.4947, 0.5580],\n",
      "         [0.4630, 0.4901, 0.9552, 0.2336, 0.9802],\n",
      "         [0.4147, 0.4719, 0.8765, 0.7198, 0.9070],\n",
      "         [0.8264, 0.2374, 0.0944, 0.4895, 0.1953]],\n",
      "\n",
      "        [[0.9034, 0.9578, 0.1266, 0.4522, 0.4032],\n",
      "         [0.2456, 0.0185, 0.1444, 0.8930, 0.6270],\n",
      "         [0.8786, 0.2491, 0.2291, 0.0037, 0.8230],\n",
      "         [0.9096, 0.9918, 0.5614, 0.6948, 0.9402]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[3, 2, 3, 0],\n",
       "        [1, 4, 4, 0],\n",
       "        [1, 3, 0, 1]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.rand(3,4,5)\n",
    "print(A)\n",
    "A.argmax(dim=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can use standard NumPy-like indexing with all bells and whistles!\n",
    "\n",
    "Example Grab the middle column of A (index = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0591,  0.6838,  0.4621],\n",
      "        [ 0.7117,  0.8484,  0.3358],\n",
      "        [ 0.4537,  0.3042,  0.0450]])\n",
      "tensor([ 0.6838,  0.8484,  0.3042])\n"
     ]
    }
   ],
   "source": [
    "A = torch.rand(3,3)\n",
    "print(A)\n",
    "print(A[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resizing: If you want to resize/reshape tensor, you can use ``torch.view``:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you have a one element tensor, use ``.item()`` to get the value as a\n",
    "Python number\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read later:**\n",
    "\n",
    "\n",
    "  100+ Tensor operations, including transposing, indexing, slicing,\n",
    "  mathematical operations, linear algebra, random numbers, etc.,\n",
    "  are described\n",
    "  `here <http://pytorch.org/docs/torch>`_.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy Bridge\n",
    "------------\n",
    "\n",
    "Converting a Torch Tensor to a NumPy array and vice versa is a breeze.\n",
    "\n",
    "The Torch Tensor and NumPy array will share their underlying memory\n",
    "locations, and changing one will change the other.\n",
    "\n",
    "### Converting a Torch Tensor to a NumPy Array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)\n",
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See how the numpy array changed in value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting NumPy Array to Torch Tensor\n",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "See how changing the np array changed the Torch Tensor automatically\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the Tensors on the CPU except a CharTensor support converting to\n",
    "NumPy and back.\n",
    "\n",
    "CUDA Tensors\n",
    "------------\n",
    "\n",
    "Tensors can be moved onto any device using the ``.to`` method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.5508, 1.0580],\n",
      "         [1.6207, 1.1363]],\n",
      "\n",
      "        [[1.9148, 1.6978],\n",
      "         [1.5459, 1.5224]]], device='cuda:0')\n",
      "tensor([[[1.5508, 1.0580],\n",
      "         [1.6207, 1.1363]],\n",
      "\n",
      "        [[1.9148, 1.6978],\n",
      "         [1.5459, 1.5224]]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# let us run this cell only if CUDA is available\n",
    "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
    "x = torch.rand(2,2,2)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ND Tensors\n",
    "When working with neural networks, you are always dealing with multidimensional arrays.  Here are some quick tricks\n",
    "#### Assume A is a 32x32 RGB image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10007f987518>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 3D Tensors\n",
    "import torch\n",
    "A = torch.rand(32,32,3)\n",
    "plt.imshow(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing Tensors  - grab 'RED' dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 32])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_data = A[:,:,0] #0 represents the first channel of RGB\n",
    "red_data.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swap the RGB dimension and make the tensor a 3x32x32 tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "A_rgb_first = A.permute(2,0,1)\n",
    "print(A_rgb_first.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a BatchSize to our Image Tensor\n",
    "Usually you need to do this to run inference on your trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 32, 3])\n",
      "torch.Size([32, 32, 3])\n"
     ]
    }
   ],
   "source": [
    "Anew = A.unsqueeze(0)\n",
    "print(Anew.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the tensor dimension.  \n",
    "\n",
    "sometimes like in the example above, you might have a tensor with on of the dimensions equal to one.  Use **squeeze()** to drop that dimension>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 32, 3])\n"
     ]
    }
   ],
   "source": [
    "print(Anew.squeeze(0).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
